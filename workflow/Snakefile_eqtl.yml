from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
HTTP = HTTPRemoteProvider()

import os
import pandas

###############################################################################
# General config
public_data_dir_path = config['public_data_dir'] # db path
process_data_dir_path = config['process_data_dir'] # singularity image
window = config['window'] # colocalisation window
region = config['region'] # 'genome' or region in the form 1:10-100
#out_tsv = config['out_tsv'] # output file in ODS file
#out_ods = config['out_ods'] # output file in ODS file
#db_sqlite = config['db_sqlite'] # db path
#image_sif = config['image_sif'] # singularity image

###############################################################################
# eQTL config
if "eqtl_tsv" in config:
    eqtl_tsv_path = config["eqtl_tsv"] # path to the eqtl< ods list
else:
    from eqtl2gwas.URL import URL
    url = 'https://raw.githubusercontent.com/eQTL-Catalogue/eQTL-Catalogue-resources/master/tabix/tabix_ftp_paths.tsv'
    eqtl_tsv_path = URL(url=url).download()
    config["eqtl_tsv"] = eqtl_tsv_path
eqtl_df = pandas.read_csv(eqtl_tsv_path, sep="\t")
# keep urls containing "ge" or "microarray"
eqtl_df = eqtl_df.loc[eqtl_df['ftp_path'].str.contains('/ge/|/microarray/',regex=True,na=False), ]
eqtl_id_lst = (eqtl_df['ftp_path'].str.replace('.all.tsv.gz', '', regex=True)).str.split('/', expand=True)[10].tolist()
eqtl_df.index = eqtl_id_lst
eqtl_fdr=str(config["eqtl_fdr"]) # gwas p-value, eg. 5e-8

###############################################################################
# GWAS config
#gwas_ods_path = config["gwas_ods"] # path to the gwas ods list
#gwas_df = pandas.read_excel(gwas_ods_path, header=0)
#gwas_df['trait_name'] = gwas_df['trait_name'].str.replace("'", "")
#gwas_identifier_lst = gwas_df['identifier'].tolist()
#gwas_traitname_lst = gwas_df['trait_name'].tolist()
#gwas_dic = dict(zip(gwas_identifier_lst, gwas_traitname_lst))

#container: image_sif

rule all:
    input:
        expand(os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.permuted.regions.tsv"), zip, eqtl_id=eqtl_id_lst, study=eqtl_df['study'].tolist(), quant_method=eqtl_df['quant_method'].tolist()),
        expand(os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.tsv.gz"), zip, eqtl_id=eqtl_id_lst, study=eqtl_df['study'].tolist(), quant_method=eqtl_df['quant_method'].tolist()),
        expand(os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.tsv.gz.tbi"), zip, eqtl_id=eqtl_id_lst, study=eqtl_df['study'].tolist(), quant_method=eqtl_df['quant_method'].tolist()),
        expand(os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.regions.tsv.gz.tbi"), zip, eqtl_id=eqtl_id_lst, study=eqtl_df['study'].tolist(), quant_method=eqtl_df['quant_method'].tolist()),
        expand(os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.regions.tsv.gz"), zip, eqtl_id=eqtl_id_lst, study=eqtl_df['study'].tolist(), quant_method=eqtl_df['quant_method'].tolist()),

rule eqtl_region_all_index:
    input:
        all=os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.regions.tsv.gz"),
    output:
        tbi=os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.regions.tsv.gz.tbi"),
    shell:
        """tabix -s 2 -b 3 -e 3 {input.all}"""

rule eqtl_region_all:
    input:
        all=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.tsv.gz"),
        region=os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.region.tsv"),
    output:
        all=os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.regions.tsv.gz"),
    shell:
        """tabix {input.all} -R {input.region} |sort -k2,2 -k3,3n |bgzip > {output.all}"""

rule extract_eqtlleads:
    input:
        permuted=os.path.join(process_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.permuted.tsv"),
    output:
        leadpair=os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.leadpair.tsv"),
        region=os.path.join(process_data_dir_path, "fdr"+str(eqtl_fdr), "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.region.tsv"),
    params:
        region=region,  # 7:6000000-7000000
        eqtl_fdr=eqtl_fdr,  # 7:6000000-7000000
    shell:
        """python workflow/scripts/extract_lead_eqtls.py {input.permuted} {output.leadpair} {output.region} {params.region} {params.eqtl_fdr}"""

rule gunzip_eqtl_permuted:
    input:
        permuted=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.permuted.tsv.gz"),
    output:
        permuted=os.path.join(process_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.permuted.tsv"),
    shell:
        """gunzip -c {input.permuted} > {output.permuted}"""

rule dwnld_eqtl_permuted:
    input:
        md5sum=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/md5sum.txt"),
    output:
        permuted=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.permuted.tsv.gz"),
    params:
        url="ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.permuted.tsv.gz",
        public_data_dir_path=public_data_dir_path,
    shell:
        """wget -nc -q -r {params.url} -P {params.public_data_dir_path}
        python workflow/scripts/md5sum_check.py {output.permuted} {input.md5sum}"""

rule dwnld_eqtl_tbi:
    input:
        md5sum=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/md5sum.txt"),
    output:
        tbi=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.tsv.gz.tbi"),
    params:
        url="ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.tsv.gz.tbi",
        public_data_dir_path=public_data_dir_path,
    shell:
        """wget -nc -q -r {params.url} -P {params.public_data_dir_path}
        python workflow/scripts/md5sum_check.py {output.tbi} {input.md5sum}"""

rule dwnld_eqtl_all:
    input:
        md5sum=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/md5sum.txt"),
    output:
        all=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.tsv.gz"),
    params:
        url="ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_id}.all.tsv.gz",
        public_data_dir_path=public_data_dir_path,
    shell:
        """wget -nc -q -r {params.url} -P {params.public_data_dir_path}
        python workflow/scripts/md5sum_check.py {output.all} {input.md5sum}"""

rule dwnld_eqtl_md5sum:
    output:
        md5sum=os.path.join(public_data_dir_path, "ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/md5sum.txt"),
    params:
        url="ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/md5sum.txt",
        public_data_dir_path=public_data_dir_path,
    shell:
        """wget -nc -q -r {params.url} -P {params.public_data_dir_path}"""
