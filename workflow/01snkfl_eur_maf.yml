import pandas

# config
chr_lst = range(1, 23)
maf_sqlite = config['maf_sqlite']
outdir_maf = config['outdir_maf']
process_data_dir = config['process_data_dir']
public_data_dir = config['public_data_dir']

# Used for testing one chromosome
if "chr" in config:
    chr_lst = [int(config['chr'])]

# variables
genotypes_vcf_gz_url="ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20130502/ALL.chr{CHR}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz"
genotypes_eur_af_tsv_gz_url="ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20130502/ALL.chr{CHR}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.eur_af.tsv.gz"
genotypes_eur_af2_tsv_gz_url="ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20130502/ALL.chr{CHR}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.eur_af2.tsv.gz"

rule all_dwnld_1kg:
    input:
        expand(os.path.join(outdir_maf, "sqlite_touched_chrom/{CHR}"), CHR=chr_lst),

rule maf_to_sqlite:
    input:
        os.path.join(process_data_dir, genotypes_eur_af2_tsv_gz_url),
    output:
        os.path.join(outdir_maf, "sqlite_touched_chrom/{CHR}"),
    params:
        maf_sqlite,
    resources: db_maf=1
    run:
        cmd_str = "sqlite3 " + params[0] + " 'create table IF NOT EXISTS eur_af (chrom INTEGER, pos INTEGER, id TEXT, ref TEXT, alt TEXT, eur_af REAL, PRIMARY KEY(id))'"
        subprocess.Popen(shlex.split(cmd_str)).communicate()
        engine = create_engine('sqlite:///' + params[0], echo=False)
        df = pandas.read_csv(input[0], sep="\t", header=None, names=['chrom', 'pos', 'id', 'ref', 'alt', 'eur_af'])
        df.to_sql('eur_af', con=engine, if_exists='append', index=False, method=sql_insert_ignore)
        Path(output[0]).touch()

rule process_maf:
    input:
        os.path.join(process_data_dir, genotypes_eur_af_tsv_gz_url),
    output:
        os.path.join(process_data_dir, genotypes_eur_af2_tsv_gz_url),
    run:
        df=pandas.read_csv(input[0], sep="\t", header=None)
        df.columns = ['chrom', 'pos', 'id', 'ref', 'alt', 'eur_af']
        df.drop_duplicates(subset=['id'], keep=False, inplace=True)
        df.to_csv(output[0], sep="\t", index=False, header=None)

rule maf_to_tsv:
    input:
        os.path.join(public_data_dir, genotypes_vcf_gz_url),
    output:
        os.path.join(process_data_dir, genotypes_eur_af_tsv_gz_url),
    threads: 2
    shell:
        """bcftools query -f '%CHROM\t%POS\t%ID\t%REF\t%ALT\t%INFO/EUR_AF\n' {input[0]} |gzip >{output[0]}"""

rule dwnld_g1k:
    output:
        os.path.join(public_data_dir, genotypes_vcf_gz_url),
    params:
        genotypes_vcf_gz_url,
        public_data_dir,
    shell:
        """wget -c -q -r {params[0]} -P {params[1]}"""
