from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
HTTP = HTTPRemoteProvider()

import os
import pandas

# eQTLs
if "eqtl_tsv" in config:
    eqtl_tsv_path = config["eqtl_tsv"] # path to the eqtl< ods list
else:
    from eqtl2gwas.URL import URL
    url = 'https://raw.githubusercontent.com/eQTL-Catalogue/eQTL-Catalogue-resources/master/tabix/tabix_ftp_paths.tsv'
    eqtl_tsv_path = URL(url=url).download()
    config["eqtl_tsv"] = eqtl_tsv_path
eqtl_df = pandas.read_csv(eqtl_tsv_path, sep="\t")
# keep urls containing "ge" or "microarray"
eqtl_df = eqtl_df.loc[eqtl_df['ftp_path'].str.contains('/ge/|/microarray/',regex=True,na=False), ]
eqtl_identifier_lst = (eqtl_df['ftp_path'].str.replace('.all.tsv.gz', '', regex=True)).str.split('/', expand=True)[10].tolist()
eqtl_df.index = eqtl_identifier_lst

# configuration
gwas_pval=str(config["gwas_pval"]) # gwas p-value, eg. 5e-8
window = config['window'] # colocalisation window, eg 500000
region = config['region'] # 'genome' or region in the form 1:10-100
out_tsv = config['out_tsv'] # output file in ODS file
out_ods = config['out_ods'] # output file in ODS file
db_sqlite = config['db_sqlite'] # db path
image_sif = config['image_sif'] # singularity image

# GWAS
gwas_ods_path = config["gwas_ods"] # path to the gwas ods list
gwas_df = pandas.read_excel(gwas_ods_path, header=0)
gwas_df['trait_name'] = gwas_df['trait_name'].str.replace("'", "")
gwas_identifier_lst = gwas_df['identifier'].tolist()
gwas_traitname_lst = gwas_df['trait_name'].tolist()
gwas_dic = dict(zip(gwas_identifier_lst, gwas_traitname_lst))

container: image_sif

rule all:
    input:
        coloc_tsv=config['out_ods'],

rule cat_tsv_sql:
    input:
        expand(os.path.join("results", "coloc", region, gwas_pval ,str(window), "{eqtl_identifier}/{gwas_identifier}.tsv"), eqtl_identifier=eqtl_identifier_lst, gwas_identifier=gwas_identifier_lst),
    output:
        coloc_tsv=config['out_tsv'],
        coloc_ods=config['out_ods'],
    params:
        coloc_dir=os.path.join("results" ,"coloc", region, gwas_pval, str(window)),
        db_path=db_sqlite,
        eqtl_tsv_path=config["eqtl_tsv"],
        gwas_ods_path=config["gwas_ods"],
    log:
        os.path.join("logs", config['out_ods'] + ".log"),
    shell:
        """
        python workflow/scripts/cat_tsv_sql.py {eqtl_tsv_path} {gwas_ods_path} {params.coloc_dir} {output.coloc_tsv} {output.coloc_ods} {params.db_path}
        """

rule coloc:
    input:
        eqtlleads_hg38_tsv="results/hg38/eqtlleadpairs/" + region + "/{eqtl_identifier}.leadpairs.tsv",
        eqtl_all_tsv_gz=lambda w: eqtl_df.loc[w.eqtl_identifier, "ftp_path"].replace("ftp://", ""),
        eqtl_all_tsv_gz_tbi=lambda w: eqtl_df.loc[w.eqtl_identifier, "ftp_path"].replace("ftp://", "") + ".tbi",
        md5sum=lambda w: os.path.dirname(eqtl_df.loc[w.eqtl_identifier, "ftp_path"].replace("ftp://", "")) + "/md5sum.txt",
        gwastop_hg38_tsv="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg38.tsv",
        gwas_vcf_gz="resources/hg38/gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}_hg38_sorted.vcf.gz",
        gwas_vcf_gz_tbi="resources/hg38/gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}_hg38_sorted.vcf.gz.tbi",
    output:
        coloc_tsv=os.path.join("results/coloc", region, gwas_pval, str(window), "{eqtl_identifier}/{gwas_identifier}.tsv"),
    log:
        os.path.join("logs/coloc", region, gwas_pval, str(window), "{eqtl_identifier}/{gwas_identifier}.log"),
    params:
        window = window,
        gwas_identifier="{gwas_identifier}",
        eqtl_identifier="{eqtl_identifier}",
        gwas_trait_name=lambda w: "{gwas_trait_name}".format(gwas_trait_name=(gwas_dic[w.gwas_identifier])),
        bcftools="/opt/miniconda/envs/myenv/bin/bcftools",
    shell:
        """
        Rscript workflow/scripts/run_coloc.R {params.window} {params.eqtl_identifier} {input.eqtlleads_hg38_tsv} {input.eqtl_all_tsv_gz} {params.gwas_identifier} '{params.gwas_trait_name}' {input.gwastop_hg38_tsv} {input.gwas_vcf_gz} {output.coloc_tsv} {params.bcftools}
        """

rule gwas_tophits_hg38:
    input:
        tophits_hg19_tsv="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg19.tsv",
        tophits_hg38_bed="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg38.bed",
    output:
        tophits_hg19_tsv="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg38.tsv",
    shell:
        "Rscript workflow/scripts/gwas_tophits_hg38.R {input.tophits_hg19_tsv} {input.tophits_hg38_bed} {output.tophits_hg19_tsv}"

rule gwas_tophits_liftover_hg38:
    input:
        chain_gz=HTTP.remote("ftp.ensembl.org/pub/assembly_mapping/homo_sapiens/GRCh37_to_GRCh38.chain.gz", keep_local=True, insecure=True),
        tophits_hg19_bed="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg19.bed",
    output:
        tophits_hg38_bed="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg38.bed",
    shell:
        "CrossMap.py bed {input.chain_gz} {input.tophits_hg19_bed} {output.tophits_hg38_bed}"

rule gwas_tophits_hg19:
    output:
        tophits_hg19_tsv="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg19.tsv",
        tophits_hg19_bed="results/gwas/" + gwas_pval + "/{gwas_identifier}_hg19.bed",
    params:
        gwas_pval = gwas_pval,
        gwas_identifier="{gwas_identifier}",
    shell:
        "Rscript workflow/scripts/gwasglue_tophits.R {params.gwas_identifier} {params.gwas_pval} {output.tophits_hg19_tsv} {output.tophits_hg19_bed}"

rule gwas_hg38_tabix:
    input:
        vcf_gz="resources/hg38/gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}_hg38_sorted.vcf.gz",
    output:
        gwas_vcf_gz_tbi="resources/hg38/gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}_hg38_sorted.vcf.gz.tbi",
    shell:
        "tabix -p vcf {input.vcf_gz}"

rule gwas_hg38_sort:
    input:
        hg38_vcf_gz="resources/hg38/gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}_hg38.vcf.gz",
    output:
        sorted_vcf_gz="resources/hg38/gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}_hg38_sorted.vcf.gz",
    shell:
        "bcftools sort -O z {input.hg38_vcf_gz} -o {output.sorted_vcf_gz}"

rule gwas_liftover_hg38:
    input:
        vcf_gz=HTTP.remote("gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}.vcf.gz", keep_local=True, insecure=True),
        chain_gz="ftp.ensembl.org/pub/assembly_mapping/homo_sapiens/GRCh37_to_GRCh38.chain.gz",
        genome="resources/ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa",
    output:
        hg38_vcf_gz="resources/hg38/gwas.mrcieu.ac.uk/files/{gwas_identifier}/{gwas_identifier}_hg38.vcf.gz",
    shell:
        "CrossMap.py vcf --compress {input.chain_gz} {input.vcf_gz} {input.genome} {output.hg38_vcf_gz}"

rule dwnld_chain:
    output:
        chain_gz="ftp.ensembl.org/pub/assembly_mapping/homo_sapiens/GRCh37_to_GRCh38.chain.gz",
    shell:
        """wget -q -N -x {output.chain_gz}"""

rule dwnld_ref_fasta:
    input:
        HTTP.remote("ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz", keep_local=False, insecure=True),
    output:
        fa="resources/ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa",
    run:
        shell("gunzip -c {input} > {output.fa}")

rule extract_eqtlleads:
    input:
        permuted="resources/hg38/ebi/eqtl/{eqtl_identifier}.permuted.tsv",
    output:
        eqtlleads_hg38_tsv="results/hg38/eqtlleadpairs/" + region + "/{eqtl_identifier}.leadpairs.tsv",
    params:
        region=region,  # 7:6000000-7000000
    shell:
        """Rscript workflow/scripts/extract_lead_var_pairs.R {input.permuted} {output.eqtlleads_hg38_tsv} {params.region}"""


rule dwnld_eqtl_md5sum:
    output:
        md5sum=os.path.join("ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/md5sum.txt"),
    shell:
        """wget -q -N -x {output.md5sum}"""

rule dwnld_eqtl_all:
    input:
        md5sum=lambda w: os.path.join("ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats", eqtl_df.loc[w.eqtl_identifier, "study"], eqtl_df.loc[w.eqtl_identifier, "quant_method"], "md5sum.txt"),
    output:
        all="ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_identifier}.all.tsv.gz",
    shell:
        """wget -q -N -x {output.all}
        python workflow/scripts/md5sum_check.py {output.all} {input.md5sum}
        """

rule dwnld_eqtl_tbi:
    input:
        md5sum=lambda w: os.path.join("ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats", eqtl_df.loc[w.eqtl_identifier, "study"], eqtl_df.loc[w.eqtl_identifier, "quant_method"], "md5sum.txt"),
    output:
        tbi="ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_identifier}.all.tsv.gz.tbi",
    shell:
        """wget -q -N -x {output.tbi}
        python workflow/scripts/md5sum_check.py {output.tbi} {input.md5sum}"""

rule gunzip_eqtl_permuted:
    input:
        permuted=lambda w: eqtl_df.loc[w.eqtl_identifier, 'ftp_path'].replace('.all.', '.permuted.').replace('ftp://', '')
    output:
        permuted="resources/hg38/ebi/eqtl/{eqtl_identifier}.permuted.tsv"
    shell:
        """gunzip -c {input.permuted} > {output.permuted}"""

rule dwnld_eqtl_permuted:
    input:
        md5sum=lambda w: os.path.join("ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats", eqtl_df.loc[w.eqtl_identifier, "study"], eqtl_df.loc[w.eqtl_identifier, "quant_method"], "md5sum.txt"),
    output:
        permuted="ftp.ebi.ac.uk/pub/databases/spot/eQTL/sumstats/{study}/{quant_method}/{eqtl_identifier}.permuted.tsv.gz",
    shell:
        """wget -q -N -x {output.permuted}
        python workflow/scripts/md5sum_check.py {output.permuted} {input.md5sum}"""
